# -*- coding: utf-8 -*-
"""Trabalho final - INF420.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1E0xTRuKKd3NAj7o2ulUgAzY4o5aMNyeR

### Marco Aurélio Soares Abrantes - es98887  
### Lucas Braga Moura - es98909
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np  
import matplotlib.pyplot as plt  
import seaborn as sns 
from sklearn.model_selection import train_test_split 
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import cross_val_score, GridSearchCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score, f1_score
import warnings
warnings.filterwarnings('ignore')
# %matplotlib inline

"""Carregando e exibindo o head do dataset de treino"""

train_dataset = pd.read_csv('train.csv', index_col=0)
train_dataset.head()

train_dataset.describe()

"""Carregando e exibindo o head do dataset de teste"""

test_dataset = pd.read_csv('test.csv')
test_dataset.head()

test_dataset.describe()

"""Gerando dataframe de resposta com a variável 'NU_INSCRICAO'

"""

answer = pd.DataFrame()
answer['NU_INSCRICAO'] = test_dataset['NU_INSCRICAO']
answer.head()

"""###Testando hipóteses para selecionar features

Primeira hipótese: NU_IDADE, TP_COR_RACA e IN_TREINEIRO são fracamente correlacionados com outras características.
"""

var = ['TP_COR_RACA','NU_IDADE','IN_TREINEIRO','NU_NOTA_CN','NU_NOTA_CH','NU_NOTA_LC','NU_NOTA_REDACAO']
train_dataset[var].corr()

"""Segunda hipótese: NU_IDADE, TP_COR_RACA e IN_TREINEIRO poderiam ser descartados, evitando interferências nas previsões do modelo."""

features = ['NU_NOTA_CN','NU_NOTA_CH','NU_NOTA_LC','NU_NOTA_REDACAO']

train_dataset[features].corr()

plt.figure(figsize=(9,6))
plt.title('Train Features')
sns.heatmap(train_dataset[features].corr(), annot=True, cmap='Reds')
plt.xticks(rotation=70)
plt.show()

test_dataset[features].corr()

plt.figure(figsize=(9,6))
plt.title('Test Features')
sns.heatmap(test_dataset[features].corr(), annot=True, cmap='Reds')
plt.xticks(rotation=70)
plt.show()

"""#### Pré-processamento de dados
Como existem dados nulos no conjunto de dados, há algumas abordagens que podem ser adotadas:

1) Elimine valores nulos do conjunto de dados. Poderia diminuir drasticamente as amostras para treinar o modelo;

2) Preencha os valores nulos com zeros. Ele mantém o número de amostras no conjunto de dados.

3) Preencha os valores nulos com o valor médio das feições. Ele mantém o número de amostras no conjunto de dados.

Aqui, os valores nulos serão preenchidos com zeros (segunda abordagem).
"""

train_dataset[features].isnull().sum()

train_dataset['NU_NOTA_MT'].isnull().sum()

test_dataset[features].isnull().sum()

"""Preenchendo valores nulos com zero"""

train_dataset['NU_NOTA_CN'].fillna(0, inplace=True)
train_dataset['NU_NOTA_CH'].fillna(0, inplace=True)
train_dataset['NU_NOTA_REDACAO'].fillna(0, inplace=True)
train_dataset['NU_NOTA_LC'].fillna(0, inplace=True)
train_dataset['NU_NOTA_MT'].fillna(0, inplace=True)
test_dataset['NU_NOTA_CN'].fillna(0, inplace=True)
test_dataset['NU_NOTA_CH'].fillna(0, inplace=True)
test_dataset['NU_NOTA_REDACAO'].fillna(0, inplace=True)
test_dataset['NU_NOTA_LC'].fillna(0, inplace=True)

"""Confirmando se valores nulos estão zerados"""

train_dataset[features].isnull().sum()

train_dataset['NU_NOTA_MT'].isnull().sum()

test_dataset[features].isnull().sum()

"""Dividindo o dataset

"""

X = train_dataset[features]

X.head()

y = train_dataset['NU_NOTA_MT']
y.head()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)

"""Normalização de escala de recursos

Isso significa que para cada feature, a média seria 0, e o Desvio Padrão seria 1. Desta forma, as features são padronizadas, tornando-as mais manejáveis para nossos modelos.
"""

sc = StandardScaler()
sc.fit(X_train)
X_train = sc.transform(X_train)
X_test = sc.transform(X_test)

"""#### Modelando
Regressão Linear
"""

lr = LinearRegression()
lr.fit(X_train, y_train)

"""Obtendo previsões"""

y_pred = lr.predict(X_test)

"""O coeficiente de determinação, também chamado de R², é uma medida de ajuste de um modelo estatístico linear generalizado, como a regressão linear simples ou múltipla, aos valores observados de uma variável aleatória  
Para evitar que fique enviesado
"""

r2_score(y_test, y_pred)

"""Realizando pesquisa de grade  
A pesquisa de grade é um método para encontrar a melhor combinação possível de hiperparâmetros nos quais o modelo atinge a maior precisão  
Usado para melhorar a tecnica que o randomForest usa, ao invés de mostrar aleatóriamente a distribuição, ele avalia todas avaliações que foram definidas (as features)

#### Parametros usados GridSearch CV
**estimator:** ajusta o conjunto de dados de todas combinações possíveis, dados os valores dos parâmetros que serão avaliados, a melhor combinação é mantida. O RandomForestRegressor() retorna um caminho de decisão (uma matriz) depois de analisar os parâmetros passados pra ele  
**param_grid:**  
  'max_depth': quantidade de camadas [3,7)  
  'n_estimators': O parâmetro especifica o número de árvores na floresta do modelo  
**cv:** Determina a estratégia de divisão de validação cruzada, inteiro, para especificar o número de folds em um (Stratified)KFold  
**scoring:**R² explicado acima  
**verbose:**0 para não ficar verboso  
**n_jobs:**O número de trabalhos paralelos a serem executados para pesquisa de vizinhos. -1 significa usar todos os processadores

best_result pega pega os melhores resultados de x e y do gridsearch, depois do treinamento

#### Parametros do RandomForestRegressor
pega o max_depth e n_estimators dos melhores parâmetros obtidos
"""

gsc = GridSearchCV(
    estimator=RandomForestRegressor(),
    param_grid={'max_depth': range(3,7), 
                'n_estimators': (50, 100, 500, 1000),
    },
    cv=10, scoring='r2', verbose=0, n_jobs=-1)

grid_result = gsc.fit(X, y)
best_params = grid_result.best_params_
rfr = RandomForestRegressor(max_depth=best_params["max_depth"],
                            n_estimators=best_params["n_estimators"],
                            random_state=False, verbose=False)

"""K-fold é o método de cross-validation mais conhecido e utilizado. O método consiste em dividir o dataset em k partes, usando k-1 partes para treino e a parte remanescente para teste, fazendo isso k vezes. Em cada uma das k vezes, testa-se o modelo com um fold diferente calculando a métrica escolhida para avaliação do modelo. Ao final do processo, teremos k medidas da métrica de avaliação escolhida, com as quais geralmente calculamos a média e o desvio-padrão"""

scores = cross_val_score(rfr, X, y, cv=10, scoring='r2')
scores

scores.mean() * 100

"""Fazendo o modelo de Random Forest"""

rfr.fit(train_dataset[features], train_dataset['NU_NOTA_MT'])

"""Fazendo a Previsão do modelo no dataset de teste"""

y_pred = rfr.predict(test_dataset[features])
y_pred

"""Fazendo a tabela 'NU_NOTA_MT' no dataframe de resposta e removendo nota 0 para fins de amostra dos resultados"""

answer['NU_NOTA_MT'] = y_pred
answer.mask(answer==0).ffill()

answer.describe()